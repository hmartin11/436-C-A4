{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4190a10e-880b-4c72-be80-2603ef9d73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.data.dataset_factory import FileDatasetFactory\n",
    "\n",
    "# Connect to your Azure ML Workspace\n",
    "workspace = Workspace.from_config()\n",
    "\n",
    "datastore = workspace.get_default_datastore()\n",
    "\n",
    "# Define paths for data in Azure Blob Storage\n",
    "datastore_path = \"script-mode-workflow/pickle\"\n",
    "train_data_path = os.path.join(datastore_path, \"train\")\n",
    "# Assuming your file is in a local directory named \"train_dir\" that contains \"train.pickle\"\n",
    "#local_train_dir = os.path.join(os.getcwd(), \"train_dir\")\n",
    "local_train_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dfa18fc-0f06-4a9c-a392-292dbce01530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "def pickleTrainingData():\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "\n",
    "    train_data = np.empty((0, 32*32*3))\n",
    "    train_labels = []\n",
    "\n",
    "    for i in range(1, 2):\n",
    "        fileNameDataBatch = './cifar-10-batches-py/data_batch_' + str(i)\n",
    "        batch = unpickle(fileNameDataBatch)\n",
    "        train_data = np.vstack((train_data, batch[b'data']))\n",
    "        train_labels += batch[b'labels']\n",
    "\n",
    "    train_labels = np.array(train_labels)\n",
    "    train_data = train_data.reshape(-1, 32, 32, 3) / 255.0\n",
    "    \n",
    "    # !!!!! NOTICE HOW THE DATA IS SAVED !!!!!!\n",
    "    # Will be returned in form of:\n",
    "    # train_label, train_data  = getDataBack()\n",
    "    pickle.dump([train_labels,train_data], open('./train.cnn', 'wb'))\n",
    "\n",
    "\n",
    "\n",
    "# CODE HELPER 2\n",
    "def getTestData():\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    fileNameTestBatch = './cifar-10-batches-py/test_batch'\n",
    "    test_data = unpickle(fileNameTestBatch)[b'data']\n",
    "    test_data = test_data.reshape(-1, 32, 32, 3) / 255.0\n",
    "    test_labels = np.array(unpickle(fileNameTestBatch)[b'labels'])\n",
    "    \n",
    "    num_samples_to_select = 600\n",
    "    random_indices = np.random.choice(test_data.shape[0], num_samples_to_select, replace=False)\n",
    "    selected_test_data = test_data[random_indices]\n",
    "    selected_test_labels = test_labels[random_indices]\n",
    "    \n",
    "    return selected_test_data, selected_test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f01f0fd-0a2d-44b9-b969-2e8c741645ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, label = pickleTrainingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1886807d-023a-468b-bd0d-bf6ff5ad0938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "'overwrite' is set to True. Any file already present in the target will be overwritten.\n",
      "Uploading files from '/mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11' to 'script-mode-workflow/pickle/train'\n",
      "Copying 25 files with concurrency set to 4\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/.ipynb_checkpoints/conda_dependency_file-checkpoint.yml, file 1 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/.ipynb_checkpoints/conda_dependency_file-checkpoint.yml\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/.ipynb_checkpoints/cnnDeployment-checkpoint.ipynb, file 2 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/.ipynb_checkpoints/cnnDeployment-checkpoint.ipynb\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/.ipynb_checkpoints/cnnDeployment-Copy1-checkpoint.ipynb, file 3 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/.ipynb_checkpoints/cnnDeployment-Copy1-checkpoint.ipynb\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/.ipynb_checkpoints/score-checkpoint.py, file 4 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/.ipynb_checkpoints/score-checkpoint.py\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/azureml-models/model-cnn/1/saved_model.pb, file 5 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/azureml-models/model-cnn/1/saved_model.pb\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/azureml-models/model3/1/modelCNN/saved_model.pb, file 6 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/azureml-models/model3/1/modelCNN/saved_model.pb\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/azureml-models/model3/1/modelCNN/variables/variables.index, file 7 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/azureml-models/model3/1/modelCNN/variables/variables.index\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/azureml-models/model2/1/model.pickle, file 8 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/azureml-models/model2/1/model.pickle\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/cifar-10-batches-py/batches.meta, file 9 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/cifar-10-batches-py/batches.meta\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/azureml-models/model3/1/modelCNN/variables/variables.data-00000-of-00001, file 10 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/azureml-models/model3/1/modelCNN/variables/variables.data-00000-of-00001\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/cifar-10-batches-py/data_batch_3, file 11 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/cifar-10-batches-py/data_batch_3\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/cifar-10-batches-py/data_batch_1, file 12 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/cifar-10-batches-py/data_batch_1\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/cifar-10-batches-py/data_batch_2, file 13 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/cifar-10-batches-py/data_batch_2\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/cifar-10-batches-py/readme.html, file 14 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/cifar-10-batches-py/readme.html\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/conda_dependency_file.yml, file 15 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/conda_dependency_file.yml\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/cifar-10-batches-py/data_batch_4, file 16 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/cifar-10-batches-py/data_batch_4\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/scripts/script.py, file 17 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/scripts/script.py\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/cnnDeployment-Copy1.ipynb, file 18 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/cnnDeployment-Copy1.ipynb\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/score.py, file 19 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/score.py\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/cifar-10-batches-py/test_batch, file 20 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/cifar-10-batches-py/test_batch\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/cifar-10-batches-py/data_batch_5, file 21 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/cifar-10-batches-py/data_batch_5\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/saved_model.pb, file 22 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/saved_model.pb\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/cnnDeployment.ipynb, file 23 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/cnnDeployment.ipynb\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/scripts/.ipynb_checkpoints/script-checkpoint.py, file 24 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/scripts/.ipynb_checkpoints/script-checkpoint.py\n",
      "Copied /mnt/batch/tasks/shared/LS_root/mounts/clusters/hmartin112/code/Users/hmartin11/train.cnn, file 25 out of 25. Destination path: https://a4q32845494989.blob.core.windows.net/azureml-blobstore-0024d333-c080-4c76-aca6-074663f996c9/script-mode-workflow/pickle/train/train.cnn\n",
      "Creating new dataset\n",
      "Files copied=25, skipped=0, failed=0\n"
     ]
    }
   ],
   "source": [
    "#Upload the entire directory to the datastore\n",
    "FileDatasetFactory.upload_directory(src_dir=local_train_dir,\n",
    "                                    target=(datastore, train_data_path),\n",
    "                                    overwrite=True)\n",
    "\n",
    "# Create a FileDataset pointing to the uploaded directory/files\n",
    "train_dataset = Dataset.File.from_files(path=(datastore, train_data_path))\n",
    "\n",
    "# This path can be used to access the dataset during training\n",
    "datastore_train_path = train_dataset.as_mount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eba9dfc-1a0d-4362-bf3d-46489fdd79fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"--copy_X\": True,\n",
    "    \"--fit_intercept\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dd56fc2-91cc-4420-a5fa-193e8e22da21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = Environment.from_conda_specification(name=\"sklearn-env\", file_path=\"./conda_dependency_file.yml\")\n",
    "arguments = [f'{k}={v}' for k, v in hyperparameters.items()]\n",
    "arguments.extend(['--train', datastore_train_path])\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Modify this based on your script name !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "src = ScriptRunConfig(source_directory='./scripts',\n",
    "                      script='script.py',\n",
    "                      arguments=arguments,\n",
    "                      compute_target='local',  # Using the local compute (the Compute Instance)\n",
    "                      environment=env)\n",
    "\n",
    "\n",
    "experiment = Experiment(workspace, 'modelCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2daa663e-e89c-4fac-9273-ef8a88211b66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      " - anaconda\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#conda install -c conda-forge tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab67857d-3493-484c-b5d1-a73dc9c987d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: modelCNN_1731817699_bbdc07db\n",
      "Web View: https://ml.azure.com/runs/modelCNN_1731817699_bbdc07db?wsid=/subscriptions/40d42a86-f25f-44cb-be23-4440afba7382/resourcegroups/a4-3/workspaces/a4-q3&tid=9be73e3a-3b63-4ea5-8e18-675e687d2de9\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "[2024-11-17T04:28:21.032293] Entering context manager injector.\n",
      "[2024-11-17T04:28:21.562139] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['script.py', '--copy_X=True', '--fit_intercept=True', '--train', 'DatasetConsumptionConfig:input__5179abe5'])\n",
      "[2024-11-17T04:28:21.933] Initialize DatasetContextManager.\n",
      "Script type = None\n",
      "Set Dataset input__5179abe5's target path to /tmp/input__5179abe5_modelCNN_1731817699_bbdc07db_de7309a0-918f-4c46-95e0-4755f8496e3b\n",
      "[2024-11-17T04:28:21.968] Enter __enter__ of DatasetContextManager\n",
      "[2024-11-17T04:28:21.968] SDK version: azureml-core==1.58.0 azureml-dataprep==5.1.6. Session id: 72b42113-4b3f-4f0e-bf90-e6e979ea4bef. Run id: modelCNN_1731817699_bbdc07db.\n",
      "[2024-11-17T04:28:21.968] Processing 'input__5179abe5'.\n",
      "[2024-11-17T04:28:21.968] Mode: 'mount'.\n",
      "[2024-11-17T04:28:21.968] Path on compute is specified: 'False'.\n",
      "[2024-11-17T04:28:21.968] asset_type: None, is_eval_mode: False, is_legacy_dataset: False for input: input__5179abe5\n",
      "Message: [NOT_SUPPORTED_API_USE_ATTEMPT] The [_get_steps] API has been deprecated and is no longer supported\n",
      "Payload: {\"pid\": 16611, \"rslex_version\": \"2.22.5\", \"api_name\": \"_get_steps\", \"version\": \"5.1.6\"}\n",
      "[2024-11-17T04:28:22.260] Processing dataset FileDataset\n",
      "{\n",
      "  \"definition\": \"EnginelessDataflow:\\n---\\ntype: mltable\\npaths:\\n  - pattern: \\\"azureml://subscriptions/40d42a86-f25f-44cb-be23-4440afba7382/resourcegroups/a4-3/workspaces/a4-q3/datastores/workspaceblobstore/paths/script-mode-workflow/pickle/train\\\"\\nmetadata:\\n  infer_column_types: \\\"False\\\"\\n\",\n",
      "  \"registration\": {\n",
      "    \"id\": \"de7309a0-918f-4c46-95e0-4755f8496e3b\",\n",
      "    \"name\": null,\n",
      "    \"version\": null,\n",
      "    \"workspace\": \"Workspace.create(name='a4-q3', subscription_id='40d42a86-f25f-44cb-be23-4440afba7382', resource_group='a4-3')\"\n",
      "  }\n",
      "}\n",
      "[2024-11-17T04:28:22.512] Mounting input__5179abe5 to /tmp/input__5179abe5_modelCNN_1731817699_bbdc07db_de7309a0-918f-4c46-95e0-4755f8496e3b as folder.\n",
      "[2024-11-17T04:28:22.523] Mounting INPUT_input__5179abe5 to /tmp/input__5179abe5_modelCNN_1731817699_bbdc07db_de7309a0-918f-4c46-95e0-4755f8496e3b.\n",
      "[2024-11-17T04:28:23.535] Mounted INPUT_input__5179abe5 to /tmp/input__5179abe5_modelCNN_1731817699_bbdc07db_de7309a0-918f-4c46-95e0-4755f8496e3b.\n",
      "[2024-11-17T04:28:23.537] Exit __enter__ of DatasetContextManager\n",
      "[2024-11-17T04:28:23.537783] Entering Run History Context Manager.\n",
      "[2024-11-17T04:28:23.651569] Current directory: /tmp/azureml_runs/modelCNN_1731817699_bbdc07db\n",
      "[2024-11-17T04:28:23.651632] Preparing to call script [script.py] with arguments:['--copy_X=True', '--fit_intercept=True', '--train', '$input__5179abe5']\n",
      "[2024-11-17T04:28:23.651768] After variable expansion, calling script [script.py] with arguments:['--copy_X=True', '--fit_intercept=True', '--train', '/tmp/input__5179abe5_modelCNN_1731817699_bbdc07db_de7309a0-918f-4c46-95e0-4755f8496e3b']\n",
      "\n",
      "2024-11-17 04:28:26.191994: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-11-17 04:28:26.192210: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-17 04:28:26.193021: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-11-17 04:28:26.484138: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-11-17 04:28:26.484472: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2593905000 Hz\n",
      "Epoch 1/3\n",
      "\n",
      "  1/282 [..............................] - ETA: 3:05 - loss: 2.3027 - accuracy: 0.03\n",
      "  6/282 [..............................] - ETA: 3s - loss: 2.3028 - accuracy: 0.0671\n",
      " 12/282 [>.............................] - ETA: 2s - loss: 2.3029 - accuracy: 0.07\n",
      " 18/282 [>.............................] - ETA: 2s - loss: 2.3030 - accuracy: 0.0781\n",
      " 20/282 [=>............................] - ETA: 3s - loss: 2.3031 - accuracy: 0.07\n",
      " 22/282 [=>............................] - ETA: 3s - loss: 2.3031 - accuracy: 0.08\n",
      " 24/282 [=>............................] - ETA: 4s - loss: 2.3031 - accuracy: 0.08\n",
      " 29/282 [==>...........................] - ETA: 3s - loss: 2.3032 - accuracy: 0.08\n",
      " 35/282 [==>...........................] - ETA: 3s - loss: 2.3032 - accuracy: 0.08\n",
      " 40/282 [===>..........................] - ETA: 3s - loss: 2.3032 - accuracy: 0.08\n",
      " 42/282 [===>..........................] - ETA: 3s - loss: 2.3032 - accuracy: 0.08\n",
      " 44/282 [===>..........................] - ETA: 3s - loss: 2.3032 - accuracy: 0.08\n",
      " 46/282 [===>..........................] - ETA: 3s - loss: 2.3032 - accuracy: 0.08\n",
      " 48/282 [====>.........................] - ETA: 4s - loss: 2.3032 - accuracy: 0.08\n",
      " 50/282 [====>.........................] - ETA: 4s - loss: 2.3032 - accuracy: 0.08\n",
      " 52/282 [====>.........................] - ETA: 4s - loss: 2.3032 - accuracy: 0.08\n",
      " 55/282 [====>.........................] - ETA: 4s - loss: 2.3032 - accuracy: 0.08\n",
      " 57/282 [=====>........................] - ETA: 4s - loss: 2.3032 - accuracy: 0.08\n",
      " 58/282 [=====>........................] - ETA: 4s - loss: 2.3032 - accuracy: 0.08\n",
      " 60/282 [=====>........................] - ETA: 4s - loss: 2.3032 - accuracy: 0.08\n",
      " 62/282 [=====>........................] - ETA: 4s - loss: 2.3032 - accuracy: 0.08\n",
      " 64/282 [=====>........................] - ETA: 4s - loss: 2.3032 - accuracy: 0.08\n",
      " 65/282 [=====>........................] - ETA: 4s - loss: 2.3032 - accuracy: 0.09\n",
      " 67/282 [======>.......................] - ETA: 4s - loss: 2.3032 - accuracy: 0.09\n",
      " 69/282 [======>.......................] - ETA: 4s - loss: 2.3032 - accuracy: 0.09\n",
      " 71/282 [======>.......................] - ETA: 4s - loss: 2.3032 - accuracy: 0.09\n",
      " 74/282 [======>.......................] - ETA: 4s - loss: 2.3032 - accuracy: 0.09\n",
      " 77/282 [=======>......................] - ETA: 4s - loss: 2.3032 - accuracy: 0.09\n",
      " 79/282 [=======>......................] - ETA: 4s - loss: 2.3032 - accuracy: 0.09\n",
      " 81/282 [=======>......................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      " 83/282 [=======>......................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      " 85/282 [========>.....................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      " 87/282 [========>.....................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      " 89/282 [========>.....................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      " 91/282 [========>.....................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      " 94/282 [=========>....................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      " 96/282 [=========>....................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      " 98/282 [=========>....................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      "100/282 [=========>....................] - ETA: 4s - loss: 2.3031 - accuracy: 0.0935\n",
      "101/282 [=========>....................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      "103/282 [=========>....................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      "105/282 [==========>...................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      "107/282 [==========>...................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      "109/282 [==========>...................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      "111/282 [==========>...................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      "113/282 [===========>..................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      "115/282 [===========>..................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      "117/282 [===========>..................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      "120/282 [===========>..................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      "122/282 [===========>..................] - ETA: 4s - loss: 2.3031 - accuracy: 0.09\n",
      "124/282 [============>.................] - ETA: 4s - loss: 2.3030 - accuracy: 0.09\n",
      "126/282 [============>.................] - ETA: 4s - loss: 2.3030 - accuracy: 0.09\n",
      "128/282 [============>.................] - ETA: 4s - loss: 2.3030 - accuracy: 0.09\n",
      "130/282 [============>.................] - ETA: 4s - loss: 2.3030 - accuracy: 0.09\n",
      "132/282 [=============>................] - ETA: 4s - loss: 2.3030 - accuracy: 0.09\n",
      "134/282 [=============>................] - ETA: 4s - loss: 2.3030 - accuracy: 0.09\n",
      "136/282 [=============>................] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "137/282 [=============>................] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "139/282 [=============>................] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "142/282 [==============>...............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "144/282 [==============>...............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "146/282 [==============>...............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "148/282 [==============>...............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "150/282 [==============>...............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "152/282 [===============>..............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "154/282 [===============>..............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "156/282 [===============>..............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "157/282 [===============>..............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "159/282 [===============>..............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "161/282 [================>.............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "163/282 [================>.............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "165/282 [================>.............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "167/282 [================>.............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "169/282 [================>.............] - ETA: 3s - loss: 2.3030 - accuracy: 0.0955\n",
      "171/282 [=================>............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "173/282 [=================>............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "175/282 [=================>............] - ETA: 3s - loss: 2.3030 - accuracy: 0.09\n",
      "177/282 [=================>............] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "180/282 [==================>...........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "182/282 [==================>...........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "184/282 [==================>...........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "186/282 [==================>...........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "188/282 [===================>..........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "189/282 [===================>..........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "191/282 [===================>..........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "193/282 [===================>..........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "195/282 [===================>..........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "197/282 [===================>..........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "199/282 [====================>.........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "203/282 [====================>.........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "207/282 [=====================>........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "211/282 [=====================>........] - ETA: 2s - loss: 2.3030 - accuracy: 0.09\n",
      "215/282 [=====================>........] - ETA: 1s - loss: 2.3030 - accuracy: 0.09\n",
      "220/282 [======================>.......] - ETA: 1s - loss: 2.3030 - accuracy: 0.09\n",
      "226/282 [=======================>......] - ETA: 1s - loss: 2.3030 - accuracy: 0.09\n",
      "232/282 [=======================>......] - ETA: 1s - loss: 2.3030 - accuracy: 0.09\n",
      "235/282 [========================>.....] - ETA: 1s - loss: 2.3030 - accuracy: 0.09\n",
      "237/282 [========================>.....] - ETA: 1s - loss: 2.3030 - accuracy: 0.09\n",
      "239/282 [========================>.....] - ETA: 1s - loss: 2.3030 - accuracy: 0.09\n",
      "241/282 [========================>.....] - ETA: 1s - loss: 2.3030 - accuracy: 0.09\n",
      "243/282 [========================>.....] - ETA: 1s - loss: 2.3030 - accuracy: 0.09\n",
      "245/282 [=========================>....] - ETA: 1s - loss: 2.3030 - accuracy: 0.09\n",
      "247/282 [=========================>....] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "249/282 [=========================>....] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "251/282 [=========================>....] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "253/282 [=========================>....] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "255/282 [==========================>...] - ETA: 0s - loss: 2.3030 - accuracy: 0.0953\n",
      "257/282 [==========================>...] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "259/282 [==========================>...] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "261/282 [==========================>...] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "263/282 [==========================>...] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "265/282 [===========================>..] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "267/282 [===========================>..] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "269/282 [===========================>..] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "271/282 [===========================>..] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "273/282 [============================>.] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "275/282 [============================>.] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "277/282 [============================>.] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "279/282 [============================>.] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "281/282 [============================>.] - ETA: 0s - loss: 2.3030 - accuracy: 0.09\n",
      "282/282 [==============================] - 9s 31ms/step - loss: 2.3030 - accuracy: 0.0955 - val_loss: 2.3012 - val_accuracy: 0.1010\n",
      "Epoch 2/3\n",
      "\n",
      "  1/282 [..............................] - ETA: 3s - loss: 2.2953 - accuracy: 0.15\n",
      "  5/282 [..............................] - ETA: 4s - loss: 2.2995 - accuracy: 0.10\n",
      "  7/282 [..............................] - ETA: 5s - loss: 2.3000 - accuracy: 0.09\n",
      "  9/282 [..............................] - ETA: 6s - loss: 2.3002 - accuracy: 0.09\n",
      " 11/282 [>.............................] - ETA: 7s - loss: 2.3004 - accuracy: 0.09\n",
      " 13/282 [>.............................] - ETA: 7s - loss: 2.3005 - accuracy: 0.09\n",
      " 15/282 [>.............................] - ETA: 7s - loss: 2.3006 - accuracy: 0.09\n",
      " 17/282 [>.............................] - ETA: 7s - loss: 2.3006 - accuracy: 0.09\n",
      " 19/282 [=>............................] - ETA: 7s - loss: 2.3007 - accuracy: 0.0916\n",
      " 21/282 [=>............................] - ETA: 7s - loss: 2.3007 - accuracy: 0.09\n",
      " 23/282 [=>............................] - ETA: 7s - loss: 2.3008 - accuracy: 0.09\n",
      " 25/282 [=>............................] - ETA: 7s - loss: 2.3008 - accuracy: 0.09\n",
      " 27/282 [=>............................] - ETA: 7s - loss: 2.3009 - accuracy: 0.09\n",
      " 29/282 [==>...........................] - ETA: 7s - loss: 2.3009 - accuracy: 0.09\n",
      " 34/282 [==>...........................] - ETA: 7s - loss: 2.3010 - accuracy: 0.09\n",
      " 40/282 [===>..........................] - ETA: 6s - loss: 2.3011 - accuracy: 0.09\n",
      " 46/282 [===>..........................] - ETA: 5s - loss: 2.3012 - accuracy: 0.09\n",
      " 51/282 [====>.........................] - ETA: 5s - loss: 2.3012 - accuracy: 0.09\n",
      " 56/282 [====>.........................] - ETA: 4s - loss: 2.3012 - accuracy: 0.09\n",
      " 59/282 [=====>........................] - ETA: 4s - loss: 2.3012 - accuracy: 0.09\n",
      " 65/282 [=====>........................] - ETA: 4s - loss: 2.3012 - accuracy: 0.10\n",
      " 68/282 [======>.......................] - ETA: 4s - loss: 2.3012 - accuracy: 0.10\n",
      " 70/282 [======>.......................] - ETA: 4s - loss: 2.3012 - accuracy: 0.10\n",
      " 72/282 [======>.......................] - ETA: 4s - loss: 2.3012 - accuracy: 0.10\n",
      " 74/282 [======>.......................] - ETA: 4s - loss: 2.3011 - accuracy: 0.10\n",
      " 76/282 [=======>......................] - ETA: 4s - loss: 2.3011 - accuracy: 0.10\n",
      " 78/282 [=======>......................] - ETA: 4s - loss: 2.3011 - accuracy: 0.10\n",
      " 79/282 [=======>......................] - ETA: 4s - loss: 2.3011 - accuracy: 0.10\n",
      " 81/282 [=======>......................] - ETA: 4s - loss: 2.3011 - accuracy: 0.10\n",
      " 83/282 [=======>......................] - ETA: 4s - loss: 2.3011 - accuracy: 0.10\n",
      " 84/282 [=======>......................] - ETA: 4s - loss: 2.3011 - accuracy: 0.10\n",
      " 86/282 [========>.....................] - ETA: 4s - loss: 2.3011 - accuracy: 0.10\n",
      " 88/282 [========>.....................] - ETA: 4s - loss: 2.3010 - accuracy: 0.10\n",
      " 90/282 [========>.....................] - ETA: 4s - loss: 2.3010 - accuracy: 0.10\n",
      " 92/282 [========>.....................] - ETA: 4s - loss: 2.3010 - accuracy: 0.10\n",
      " 94/282 [=========>....................] - ETA: 4s - loss: 2.3010 - accuracy: 0.10\n",
      " 97/282 [=========>....................] - ETA: 4s - loss: 2.3010 - accuracy: 0.10\n",
      " 99/282 [=========>....................] - ETA: 4s - loss: 2.3009 - accuracy: 0.10\n",
      "101/282 [=========>....................] - ETA: 4s - loss: 2.3009 - accuracy: 0.10\n",
      "103/282 [=========>....................] - ETA: 4s - loss: 2.3009 - accuracy: 0.10\n",
      "105/282 [==========>...................] - ETA: 4s - loss: 2.3009 - accuracy: 0.10\n",
      "107/282 [==========>...................] - ETA: 4s - loss: 2.3009 - accuracy: 0.10\n",
      "109/282 [==========>...................] - ETA: 4s - loss: 2.3008 - accuracy: 0.10\n",
      "111/282 [==========>...................] - ETA: 4s - loss: 2.3008 - accuracy: 0.10\n",
      "113/282 [===========>..................] - ETA: 4s - loss: 2.3008 - accuracy: 0.10\n",
      "115/282 [===========>..................] - ETA: 4s - loss: 2.3007 - accuracy: 0.10\n",
      "117/282 [===========>..................] - ETA: 4s - loss: 2.3007 - accuracy: 0.10\n",
      "119/282 [===========>..................] - ETA: 4s - loss: 2.3006 - accuracy: 0.1037\n",
      "121/282 [===========>..................] - ETA: 4s - loss: 2.3006 - accuracy: 0.10\n",
      "123/282 [============>.................] - ETA: 4s - loss: 2.3006 - accuracy: 0.10\n",
      "125/282 [============>.................] - ETA: 4s - loss: 2.3005 - accuracy: 0.10\n",
      "127/282 [============>.................] - ETA: 4s - loss: 2.3005 - accuracy: 0.10\n",
      "129/282 [============>.................] - ETA: 3s - loss: 2.3004 - accuracy: 0.10\n",
      "131/282 [============>.................] - ETA: 3s - loss: 2.3004 - accuracy: 0.10\n",
      "133/282 [=============>................] - ETA: 3s - loss: 2.3003 - accuracy: 0.10\n",
      "135/282 [=============>................] - ETA: 3s - loss: 2.3002 - accuracy: 0.10\n",
      "137/282 [=============>................] - ETA: 3s - loss: 2.3002 - accuracy: 0.10\n",
      "139/282 [=============>................] - ETA: 3s - loss: 2.3001 - accuracy: 0.10\n",
      "141/282 [==============>...............] - ETA: 3s - loss: 2.3000 - accuracy: 0.10\n",
      "143/282 [==============>...............] - ETA: 3s - loss: 2.3000 - accuracy: 0.10\n",
      "145/282 [==============>...............] - ETA: 3s - loss: 2.2999 - accuracy: 0.10\n",
      "148/282 [==============>...............] - ETA: 3s - loss: 2.2997 - accuracy: 0.10\n",
      "150/282 [==============>...............] - ETA: 3s - loss: 2.2997 - accuracy: 0.10\n",
      "152/282 [===============>..............] - ETA: 3s - loss: 2.2996 - accuracy: 0.10\n",
      "154/282 [===============>..............] - ETA: 3s - loss: 2.2994 - accuracy: 0.10\n",
      "156/282 [===============>..............] - ETA: 3s - loss: 2.2993 - accuracy: 0.10\n",
      "158/282 [===============>..............] - ETA: 3s - loss: 2.2992 - accuracy: 0.10\n",
      "160/282 [================>.............] - ETA: 3s - loss: 2.2991 - accuracy: 0.10\n",
      "163/282 [================>.............] - ETA: 3s - loss: 2.2989 - accuracy: 0.10\n",
      "166/282 [================>.............] - ETA: 3s - loss: 2.2987 - accuracy: 0.10\n",
      "170/282 [=================>............] - ETA: 3s - loss: 2.2984 - accuracy: 0.10\n",
      "174/282 [=================>............] - ETA: 2s - loss: 2.2980 - accuracy: 0.10\n",
      "179/282 [==================>...........] - ETA: 2s - loss: 2.2976 - accuracy: 0.10\n",
      "182/282 [==================>...........] - ETA: 2s - loss: 2.2973 - accuracy: 0.10\n",
      "184/282 [==================>...........] - ETA: 2s - loss: 2.2971 - accuracy: 0.10\n",
      "186/282 [==================>...........] - ETA: 2s - loss: 2.2969 - accuracy: 0.10\n",
      "188/282 [===================>..........] - ETA: 2s - loss: 2.2967 - accuracy: 0.10\n",
      "190/282 [===================>..........] - ETA: 2s - loss: 2.2965 - accuracy: 0.10\n",
      "192/282 [===================>..........] - ETA: 2s - loss: 2.2962 - accuracy: 0.10\n",
      "194/282 [===================>..........] - ETA: 2s - loss: 2.2960 - accuracy: 0.10\n",
      "196/282 [===================>..........] - ETA: 2s - loss: 2.2958 - accuracy: 0.10\n",
      "198/282 [====================>.........] - ETA: 2s - loss: 2.2956 - accuracy: 0.1096\n",
      "199/282 [====================>.........] - ETA: 2s - loss: 2.2954 - accuracy: 0.10\n",
      "201/282 [====================>.........] - ETA: 2s - loss: 2.2952 - accuracy: 0.10\n",
      "203/282 [====================>.........] - ETA: 2s - loss: 2.2950 - accuracy: 0.11\n",
      "205/282 [====================>.........] - ETA: 2s - loss: 2.2947 - accuracy: 0.11\n",
      "207/282 [=====================>........] - ETA: 2s - loss: 2.2945 - accuracy: 0.11\n",
      "209/282 [=====================>........] - ETA: 1s - loss: 2.2942 - accuracy: 0.11\n",
      "211/282 [=====================>........] - ETA: 1s - loss: 2.2939 - accuracy: 0.11\n",
      "213/282 [=====================>........] - ETA: 1s - loss: 2.2937 - accuracy: 0.11\n",
      "215/282 [=====================>........] - ETA: 1s - loss: 2.2934 - accuracy: 0.11\n",
      "217/282 [======================>.......] - ETA: 1s - loss: 2.2931 - accuracy: 0.11\n",
      "219/282 [======================>.......] - ETA: 1s - loss: 2.2928 - accuracy: 0.11\n",
      "221/282 [======================>.......] - ETA: 1s - loss: 2.2925 - accuracy: 0.11\n",
      "222/282 [======================>.......] - ETA: 1s - loss: 2.2924 - accuracy: 0.11\n",
      "224/282 [======================>.......] - ETA: 1s - loss: 2.2921 - accuracy: 0.11\n",
      "226/282 [=======================>......] - ETA: 1s - loss: 2.2918 - accuracy: 0.11\n",
      "228/282 [=======================>......] - ETA: 1s - loss: 2.2915 - accuracy: 0.11\n",
      "230/282 [=======================>......] - ETA: 1s - loss: 2.2912 - accuracy: 0.11\n",
      "232/282 [=======================>......] - ETA: 1s - loss: 2.2909 - accuracy: 0.11\n",
      "234/282 [=======================>......] - ETA: 1s - loss: 2.2906 - accuracy: 0.11\n",
      "236/282 [========================>.....] - ETA: 1s - loss: 2.2903 - accuracy: 0.11\n",
      "238/282 [========================>.....] - ETA: 1s - loss: 2.2900 - accuracy: 0.11\n",
      "240/282 [========================>.....] - ETA: 1s - loss: 2.2896 - accuracy: 0.11\n",
      "242/282 [========================>.....] - ETA: 1s - loss: 2.2893 - accuracy: 0.11\n",
      "246/282 [=========================>....] - ETA: 1s - loss: 2.2887 - accuracy: 0.11\n",
      "252/282 [=========================>....] - ETA: 0s - loss: 2.2877 - accuracy: 0.11\n",
      "254/282 [==========================>...] - ETA: 0s - loss: 2.2873 - accuracy: 0.11\n",
      "257/282 [==========================>...] - ETA: 0s - loss: 2.2868 - accuracy: 0.11\n",
      "259/282 [==========================>...] - ETA: 0s - loss: 2.2864 - accuracy: 0.11\n",
      "260/282 [==========================>...] - ETA: 0s - loss: 2.2862 - accuracy: 0.11\n",
      "262/282 [==========================>...] - ETA: 0s - loss: 2.2859 - accuracy: 0.11\n",
      "264/282 [===========================>..] - ETA: 0s - loss: 2.2855 - accuracy: 0.11\n",
      "266/282 [===========================>..] - ETA: 0s - loss: 2.2851 - accuracy: 0.11\n",
      "267/282 [===========================>..] - ETA: 0s - loss: 2.2849 - accuracy: 0.11\n",
      "268/282 [===========================>..] - ETA: 0s - loss: 2.2848 - accuracy: 0.1167\n",
      "269/282 [===========================>..] - ETA: 0s - loss: 2.2846 - accuracy: 0.11\n",
      "271/282 [===========================>..] - ETA: 0s - loss: 2.2842 - accuracy: 0.11\n",
      "273/282 [============================>.] - ETA: 0s - loss: 2.2838 - accuracy: 0.11\n",
      "275/282 [============================>.] - ETA: 0s - loss: 2.2834 - accuracy: 0.11\n",
      "277/282 [============================>.] - ETA: 0s - loss: 2.2831 - accuracy: 0.11\n",
      "279/282 [============================>.] - ETA: 0s - loss: 2.2827 - accuracy: 0.11\n",
      "281/282 [============================>.] - ETA: 0s - loss: 2.2823 - accuracy: 0.11\n",
      "282/282 [==============================] - 8s 30ms/step - loss: 2.2819 - accuracy: 0.1183 - val_loss: 2.0819 - val_accuracy: 0.2190\n",
      "Epoch 3/3\n",
      "\n",
      "  1/282 [..............................] - ETA: 9s - loss: 2.0949 - accuracy: 0.34\n",
      "  4/282 [..............................] - ETA: 5s - loss: 2.0838 - accuracy: 0.25\n",
      " 10/282 [>.............................] - ETA: 3s - loss: 2.0876 - accuracy: 0.22\n",
      " 16/282 [>.............................] - ETA: 3s - loss: 2.0967 - accuracy: 0.20\n",
      " 22/282 [=>............................] - ETA: 2s - loss: 2.0963 - accuracy: 0.20\n",
      " 28/282 [=>............................] - ETA: 2s - loss: 2.0931 - accuracy: 0.20\n",
      " 34/282 [==>...........................] - ETA: 2s - loss: 2.0897 - accuracy: 0.21\n",
      " 40/282 [===>..........................] - ETA: 2s - loss: 2.0876 - accuracy: 0.21\n",
      " 46/282 [===>..........................] - ETA: 2s - loss: 2.0865 - accuracy: 0.21\n",
      " 52/282 [====>.........................] - ETA: 2s - loss: 2.0851 - accuracy: 0.21\n",
      " 55/282 [====>.........................] - ETA: 2s - loss: 2.0843 - accuracy: 0.21\n",
      " 57/282 [=====>........................] - ETA: 2s - loss: 2.0842 - accuracy: 0.21\n",
      " 59/282 [=====>........................] - ETA: 2s - loss: 2.0841 - accuracy: 0.21\n",
      " 60/282 [=====>........................] - ETA: 2s - loss: 2.0841 - accuracy: 0.21\n",
      " 63/282 [=====>........................] - ETA: 2s - loss: 2.0841 - accuracy: 0.21\n",
      " 65/282 [=====>........................] - ETA: 3s - loss: 2.0839 - accuracy: 0.21\n",
      " 67/282 [======>.......................] - ETA: 3s - loss: 2.0837 - accuracy: 0.21\n",
      " 69/282 [======>.......................] - ETA: 3s - loss: 2.0835 - accuracy: 0.21\n",
      " 71/282 [======>.......................] - ETA: 3s - loss: 2.0833 - accuracy: 0.21\n",
      " 73/282 [======>.......................] - ETA: 3s - loss: 2.0829 - accuracy: 0.21\n",
      " 75/282 [======>.......................] - ETA: 3s - loss: 2.0827 - accuracy: 0.21\n",
      " 77/282 [=======>......................] - ETA: 3s - loss: 2.0825 - accuracy: 0.21\n",
      " 79/282 [=======>......................] - ETA: 3s - loss: 2.0823 - accuracy: 0.2155\n",
      " 81/282 [=======>......................] - ETA: 3s - loss: 2.0821 - accuracy: 0.21\n",
      " 83/282 [=======>......................] - ETA: 3s - loss: 2.0820 - accuracy: 0.21\n",
      " 85/282 [========>.....................] - ETA: 3s - loss: 2.0820 - accuracy: 0.21\n",
      " 87/282 [========>.....................] - ETA: 3s - loss: 2.0819 - accuracy: 0.21\n",
      " 92/282 [========>.....................] - ETA: 3s - loss: 2.0817 - accuracy: 0.21\n",
      " 97/282 [=========>....................] - ETA: 3s - loss: 2.0814 - accuracy: 0.21\n",
      "102/282 [=========>....................] - ETA: 3s - loss: 2.0811 - accuracy: 0.21\n",
      "108/282 [==========>...................] - ETA: 3s - loss: 2.0808 - accuracy: 0.21\n",
      "114/282 [===========>..................] - ETA: 2s - loss: 2.0803 - accuracy: 0.21\n",
      "119/282 [===========>..................] - ETA: 2s - loss: 2.0799 - accuracy: 0.21\n",
      "121/282 [===========>..................] - ETA: 2s - loss: 2.0797 - accuracy: 0.21\n",
      "123/282 [============>.................] - ETA: 2s - loss: 2.0795 - accuracy: 0.21\n",
      "125/282 [============>.................] - ETA: 2s - loss: 2.0794 - accuracy: 0.21\n",
      "127/282 [============>.................] - ETA: 2s - loss: 2.0793 - accuracy: 0.21\n",
      "129/282 [============>.................] - ETA: 2s - loss: 2.0791 - accuracy: 0.21\n",
      "131/282 [============>.................] - ETA: 2s - loss: 2.0790 - accuracy: 0.22\n",
      "133/282 [=============>................] - ETA: 2s - loss: 2.0789 - accuracy: 0.22\n",
      "135/282 [=============>................] - ETA: 2s - loss: 2.0788 - accuracy: 0.22\n",
      "137/282 [=============>................] - ETA: 2s - loss: 2.0787 - accuracy: 0.22\n",
      "139/282 [=============>................] - ETA: 2s - loss: 2.0786 - accuracy: 0.22\n",
      "141/282 [==============>...............] - ETA: 2s - loss: 2.0785 - accuracy: 0.22\n",
      "143/282 [==============>...............] - ETA: 2s - loss: 2.0784 - accuracy: 0.22\n",
      "146/282 [==============>...............] - ETA: 2s - loss: 2.0782 - accuracy: 0.22\n",
      "149/282 [==============>...............] - ETA: 2s - loss: 2.0779 - accuracy: 0.22\n",
      "151/282 [===============>..............] - ETA: 2s - loss: 2.0778 - accuracy: 0.22\n",
      "152/282 [===============>..............] - ETA: 2s - loss: 2.0777 - accuracy: 0.22\n",
      "153/282 [===============>..............] - ETA: 2s - loss: 2.0777 - accuracy: 0.22\n",
      "155/282 [===============>..............] - ETA: 2s - loss: 2.0775 - accuracy: 0.22\n",
      "158/282 [===============>..............] - ETA: 2s - loss: 2.0773 - accuracy: 0.22\n",
      "162/282 [================>.............] - ETA: 2s - loss: 2.0771 - accuracy: 0.22\n",
      "167/282 [================>.............] - ETA: 2s - loss: 2.0768 - accuracy: 0.22\n",
      "172/282 [=================>............] - ETA: 2s - loss: 2.0765 - accuracy: 0.22\n",
      "177/282 [=================>............] - ETA: 2s - loss: 2.0761 - accuracy: 0.22\n",
      "180/282 [==================>...........] - ETA: 2s - loss: 2.0759 - accuracy: 0.2235\n",
      "182/282 [==================>...........] - ETA: 2s - loss: 2.0757 - accuracy: 0.22\n",
      "184/282 [==================>...........] - ETA: 2s - loss: 2.0756 - accuracy: 0.22\n",
      "186/282 [==================>...........] - ETA: 2s - loss: 2.0754 - accuracy: 0.22\n",
      "188/282 [===================>..........] - ETA: 2s - loss: 2.0753 - accuracy: 0.22\n",
      "191/282 [===================>..........] - ETA: 1s - loss: 2.0750 - accuracy: 0.22\n",
      "194/282 [===================>..........] - ETA: 1s - loss: 2.0748 - accuracy: 0.22\n",
      "196/282 [===================>..........] - ETA: 1s - loss: 2.0747 - accuracy: 0.22\n",
      "198/282 [====================>.........] - ETA: 1s - loss: 2.0745 - accuracy: 0.22\n",
      "200/282 [====================>.........] - ETA: 1s - loss: 2.0743 - accuracy: 0.22\n",
      "202/282 [====================>.........] - ETA: 1s - loss: 2.0742 - accuracy: 0.22\n",
      "204/282 [====================>.........] - ETA: 1s - loss: 2.0740 - accuracy: 0.22\n",
      "206/282 [====================>.........] - ETA: 1s - loss: 2.0738 - accuracy: 0.22\n",
      "208/282 [=====================>........] - ETA: 1s - loss: 2.0737 - accuracy: 0.22\n",
      "210/282 [=====================>........] - ETA: 1s - loss: 2.0735 - accuracy: 0.22\n",
      "212/282 [=====================>........] - ETA: 1s - loss: 2.0734 - accuracy: 0.22\n",
      "214/282 [=====================>........] - ETA: 1s - loss: 2.0732 - accuracy: 0.22\n",
      "216/282 [=====================>........] - ETA: 1s - loss: 2.0730 - accuracy: 0.22\n",
      "218/282 [======================>.......] - ETA: 1s - loss: 2.0729 - accuracy: 0.22\n",
      "220/282 [======================>.......] - ETA: 1s - loss: 2.0727 - accuracy: 0.22\n",
      "222/282 [======================>.......] - ETA: 1s - loss: 2.0726 - accuracy: 0.22\n",
      "224/282 [======================>.......] - ETA: 1s - loss: 2.0724 - accuracy: 0.22\n",
      "226/282 [=======================>......] - ETA: 1s - loss: 2.0723 - accuracy: 0.22\n",
      "228/282 [=======================>......] - ETA: 1s - loss: 2.0722 - accuracy: 0.22\n",
      "230/282 [=======================>......] - ETA: 1s - loss: 2.0720 - accuracy: 0.22\n",
      "232/282 [=======================>......] - ETA: 1s - loss: 2.0719 - accuracy: 0.22\n",
      "234/282 [=======================>......] - ETA: 1s - loss: 2.0718 - accuracy: 0.22\n",
      "236/282 [========================>.....] - ETA: 1s - loss: 2.0716 - accuracy: 0.22\n",
      "238/282 [========================>.....] - ETA: 1s - loss: 2.0715 - accuracy: 0.22\n",
      "240/282 [========================>.....] - ETA: 0s - loss: 2.0714 - accuracy: 0.22\n",
      "242/282 [========================>.....] - ETA: 0s - loss: 2.0712 - accuracy: 0.22\n",
      "243/282 [========================>.....] - ETA: 0s - loss: 2.0711 - accuracy: 0.22\n",
      "244/282 [========================>.....] - ETA: 0s - loss: 2.0711 - accuracy: 0.22\n",
      "246/282 [=========================>....] - ETA: 0s - loss: 2.0709 - accuracy: 0.22\n",
      "248/282 [=========================>....] - ETA: 0s - loss: 2.0708 - accuracy: 0.22\n",
      "250/282 [=========================>....] - ETA: 0s - loss: 2.0707 - accuracy: 0.2274\n",
      "252/282 [=========================>....] - ETA: 0s - loss: 2.0705 - accuracy: 0.22\n",
      "254/282 [==========================>...] - ETA: 0s - loss: 2.0704 - accuracy: 0.22\n",
      "256/282 [==========================>...] - ETA: 0s - loss: 2.0702 - accuracy: 0.22\n",
      "258/282 [==========================>...] - ETA: 0s - loss: 2.0701 - accuracy: 0.22\n",
      "260/282 [==========================>...] - ETA: 0s - loss: 2.0700 - accuracy: 0.22\n",
      "262/282 [==========================>...] - ETA: 0s - loss: 2.0698 - accuracy: 0.22\n",
      "264/282 [===========================>..] - ETA: 0s - loss: 2.0697 - accuracy: 0.22\n",
      "266/282 [===========================>..] - ETA: 0s - loss: 2.0695 - accuracy: 0.22\n",
      "268/282 [===========================>..] - ETA: 0s - loss: 2.0694 - accuracy: 0.22\n",
      "270/282 [===========================>..] - ETA: 0s - loss: 2.0692 - accuracy: 0.22\n",
      "272/282 [===========================>..] - ETA: 0s - loss: 2.0691 - accuracy: 0.22\n",
      "274/282 [============================>.] - ETA: 0s - loss: 2.0689 - accuracy: 0.22\n",
      "276/282 [============================>.] - ETA: 0s - loss: 2.0688 - accuracy: 0.22\n",
      "278/282 [============================>.] - ETA: 0s - loss: 2.0687 - accuracy: 0.22\n",
      "280/282 [============================>.] - ETA: 0s - loss: 2.0685 - accuracy: 0.22\n",
      "282/282 [==============================] - ETA: 0s - loss: 2.0684 - accuracy: 0.22\n",
      "282/282 [==============================] - 8s 28ms/step - loss: 2.0683 - accuracy: 0.2290 - val_loss: 2.0169 - val_accuracy: 0.2530\n",
      "2024-11-17 04:28:52.408846: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "\n",
      "\n",
      "[2024-11-17T04:28:52.952769] The experiment completed successfully. Finalizing run...\n",
      "[2024-11-17T04:28:52.952785] Start FinalizingInRunHistory\n",
      "[2024-11-17T04:28:52.983608] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 16611\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.07450270652770996 seconds\n",
      "[2024-11-17T04:28:54.334] Enter __exit__ of DatasetContextManager\n",
      "[2024-11-17T04:28:54.334] Unmounting /tmp/input__5179abe5_modelCNN_1731817699_bbdc07db_de7309a0-918f-4c46-95e0-4755f8496e3b.\n",
      "[2024-11-17T04:28:54.382] Finishing unmounting /tmp/input__5179abe5_modelCNN_1731817699_bbdc07db_de7309a0-918f-4c46-95e0-4755f8496e3b.\n",
      "[2024-11-17T04:28:54.382] Exit __exit__ of DatasetContextManager\n",
      "[2024-11-17T04:28:54.382564] Finished context manager injector.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: modelCNN_1731817699_bbdc07db\n",
      "Web View: https://ml.azure.com/runs/modelCNN_1731817699_bbdc07db?wsid=/subscriptions/40d42a86-f25f-44cb-be23-4440afba7382/resourcegroups/a4-3/workspaces/a4-q3&tid=9be73e3a-3b63-4ea5-8e18-675e687d2de9\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'modelCNN_1731817699_bbdc07db',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2024-11-17T04:28:20.873958Z',\n",
       " 'endTimeUtc': '2024-11-17T04:29:00.51283Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  '_azureml.ClusterName': 'local',\n",
       "  'ContentSnapshotId': 'e775c1bd-7116-41a1-a007-463482bbe655'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'de7309a0-918f-4c46-95e0-4755f8496e3b'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input__5179abe5', 'mechanism': 'Mount'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'script.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--copy_X=True',\n",
       "   '--fit_intercept=True',\n",
       "   '--train',\n",
       "   'DatasetConsumptionConfig:input__5179abe5'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'input__5179abe5': {'dataLocation': {'dataset': {'id': 'de7309a0-918f-4c46-95e0-4755f8496e3b',\n",
       "      'name': None,\n",
       "      'version': None},\n",
       "     'dataPath': None,\n",
       "     'uri': None,\n",
       "     'type': None},\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'input__5179abe5',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False,\n",
       "    'options': None}},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'sklearn-env',\n",
       "   'version': 'Autosave_2024-11-17T03:35:33Z_87b0ad65',\n",
       "   'assetId': 'azureml://locations/canadacentral/workspaces/0024d333-c080-4c76-aca6-074663f996c9/environments/sklearn-env/versions/Autosave_2024-11-17T03:35:33Z_87b0ad65',\n",
       "   'autoRebuild': True,\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['defaults'],\n",
       "     'dependencies': ['python=3.8',\n",
       "      'scikit-learn',\n",
       "      'tensorflow',\n",
       "      'pandas',\n",
       "      'numpy',\n",
       "      'pip',\n",
       "      {'pip': ['azureml-defaults']}],\n",
       "     'name': 'sklearn-env'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20240709.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://a4q32845494989.blob.core.windows.net/azureml/ExperimentRun/dcid.modelCNN_1731817699_bbdc07db/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=gkvHqbonFmy%2FEyfvC%2FXbfEEnifpetv6H33ptrQEGZ9Q%3D&skoid=dd6e7b94-bc48-4e04-951e-bd198d85d24d&sktid=9be73e3a-3b63-4ea5-8e18-675e687d2de9&skt=2024-11-17T03%3A32%3A45Z&ske=2024-11-19T03%3A42%3A45Z&sks=b&skv=2019-07-07&st=2024-11-17T04%3A19%3A02Z&se=2024-11-17T12%3A29%3A02Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://a4q32845494989.blob.core.windows.net/azureml/ExperimentRun/dcid.modelCNN_1731817699_bbdc07db/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=k7DtZgE4TRyff5oZsd3eOXBg%2BzD7lQzSR8%2Fp1VoSo9I%3D&skoid=dd6e7b94-bc48-4e04-951e-bd198d85d24d&sktid=9be73e3a-3b63-4ea5-8e18-675e687d2de9&skt=2024-11-17T03%3A32%3A45Z&ske=2024-11-19T03%3A42%3A45Z&sks=b&skv=2019-07-07&st=2024-11-17T04%3A19%3A02Z&se=2024-11-17T12%3A29%3A02Z&sp=r',\n",
       "  'logs/azureml/16611_azureml.log': 'https://a4q32845494989.blob.core.windows.net/azureml/ExperimentRun/dcid.modelCNN_1731817699_bbdc07db/logs/azureml/16611_azureml.log?sv=2019-07-07&sr=b&sig=u%2FVE%2BODDsSkZv1P7%2FFZ5UXgWf5UyuSJEiEM%2BID5Hc64%3D&skoid=dd6e7b94-bc48-4e04-951e-bd198d85d24d&sktid=9be73e3a-3b63-4ea5-8e18-675e687d2de9&skt=2024-11-17T03%3A32%3A45Z&ske=2024-11-19T03%3A42%3A45Z&sks=b&skv=2019-07-07&st=2024-11-17T04%3A18%3A23Z&se=2024-11-17T12%3A28%3A23Z&sp=r'},\n",
       " 'submittedBy': 'Hannah Martin'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = experiment.submit(src)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78f3476-cc78-4842-b537-666cfdc873c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8b09885-4ec6-4aec-9523-a27b86ddb615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "ws = Workspace.from_config()\n",
    "model_name = 'model3'\n",
    "#ws = Run.get_context().experiment.workspace\n",
    "#model_obj = Model(workspace, model_name )\n",
    "model_path = Model.get_model_path(model_name = 'model3', version=1, _workspace=ws)  # Replace with your model name\n",
    "    # Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44ac7dc9-bf0c-4d01-9be7-9d290c0652b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = Model.get_model_path('model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3dfbf0-dc73-4880-af1d-ac0f496b828b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml-models/model3/1/modelCNN\n"
     ]
    }
   ],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf812f4-f9cc-44ea-b2b5-060fd64d022b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 06:13:36.531982: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-17 06:13:36.594170: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 06:13:38.351263: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "loaded_model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33087d8a-3016-4b26-826c-98da0bdbf5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f32ab59-b20b-43e2-a4e8-6e5613367944",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 214.2594 - accuracy: 0.1150\n",
      "Test accuracy: 0.11500000208616257\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "\n",
    "test_data, test_labels = getTestData()\n",
    "test_loss, test_acc = loaded_model.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f1445-48be-429b-adb4-946af6d77090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
